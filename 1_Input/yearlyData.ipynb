{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measles\n",
      "mumps\n",
      "hepatitis\n",
      "pertussis\n"
     ]
    }
   ],
   "source": [
    "#dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, Integer, String, Float \n",
    "from sqlalchemy.orm import Session\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "from flask import Flask, jsonify, render_template\n",
    "from flask_sqlalchemy import SQLAlchemy\n",
    "import psycopg2\n",
    "\n",
    "# PyMySQL \n",
    "import pymysql\n",
    "pymysql.install_as_MySQLdb()\n",
    "\n",
    "\n",
    "#variables defined\n",
    "#master list of diseases, diseases from diseases list to use only select diseases\n",
    "#[\"measles\", \"mumps\", \"hepatitis\", \"pertussis\", \"rubella\", \"smallpox\", \"polio\"]\n",
    "diseases = [\"measles\", \"mumps\", \"hepatitis\", \"pertussis\"]\n",
    "\n",
    "\n",
    "#display diseases list\n",
    "for item in diseases:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'dataSource/contagious-diseases/measles.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a39a25bd01f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0minputPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"dataSource/contagious-diseases/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m#read csv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;31m#show data head\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1012\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1706\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'usecols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1708\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m         \u001b[0mpassed_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'dataSource/contagious-diseases/measles.csv' does not exist"
     ]
    }
   ],
   "source": [
    "#declare/clear lists\n",
    "DFTotalList = []\n",
    "DFPerCapitaList = []\n",
    "\n",
    "for item in diseases:\n",
    "      \n",
    "    #READ CSV TO DATAFRAME\n",
    "    #establish csv read path\n",
    "    inputPath = \"dataSource/contagious-diseases/\" + item + \".csv\"\n",
    "    #read csv\n",
    "    data = pd.read_csv(inputPath) \n",
    "    #show data head\n",
    "    data.head()\n",
    "    #confirm data read\n",
    "    print(\"read: \" + inputPath)\n",
    "\n",
    "    \n",
    "    ###DATA BY YEAR - PER CAPITA###\n",
    "\n",
    "    #GET YEAR FOR EACH ENTRY AND GROUPBY FOR SUM OF CASES\n",
    "    #extract year from year-week date and add to new column\n",
    "    data[\"year\"] = data['week'].astype(str).str[:-2].astype(np.int64)\n",
    "    #print new table with year column\n",
    "    #data.head()\n",
    "    #group by with sum cases per year and state_name\n",
    "    dataDF = pd.DataFrame(data.groupby([\"state_name\", \"year\", \"disease\"])[\"cases\"].sum())\n",
    "    #rename cases total per year column to include the disease name\n",
    "    #dataDF.rename(columns={\"cases\": item + \"_casesTotalPerYear\"})\n",
    "    #show data head after groupby\n",
    "    #dataDF.head()\n",
    "    \n",
    "    #WRITE DATAFRAME TO CSV\n",
    "    #establish csv write path\n",
    "    outputPath = \"inputData/\" + item + \"_totalCasesPerYear.csv\"\n",
    "    #write csv\n",
    "    dataDF.to_csv(outputPath)\n",
    "    #confirm data write\n",
    "    print(\"written: \" + outputPath)   \n",
    "    \n",
    "    #append data to DFTotalList list\n",
    "    DFTotalList.append(dataDF)\n",
    "    \n",
    "    \n",
    "    ###DATA BY YEAR - PER CAPITA###\n",
    "    \n",
    "    #GET YEAR FOR EACH ENTRY AND GROUPBY FOR SUM OF CASES\n",
    "    #extract year from year-week date and add to new column\n",
    "    data[\"year\"] = data['week'].astype(str).str[:-2].astype(np.int64)\n",
    "    #print new table with year column\n",
    "    data.head()\n",
    "    #group by with sum cases per year and state_name\n",
    "    dataDF = pd.DataFrame(data.groupby([\"state_name\", \"year\", \"disease\"])[\"incidence_per_capita\"].mean())\n",
    "    dataDF.round(5)\n",
    "    #rename cases per capita column to include the disease name\n",
    "    #dataDF = dataDF.rename(columns={\"incidence_per_capita\": item + \"_casesPerCapitaPerYear\"})\n",
    "    #show data head after groupby\n",
    "    dataDF.head()\n",
    "    \n",
    "    #WRITE CSV TO DATAFRAME\n",
    "    #establish csv write path\n",
    "    outputPath = \"inputData/\" + item + \"_perCapitaCasesPerYear.csv\"\n",
    "    #write csv\n",
    "    dataDF.to_csv(outputPath)\n",
    "    #confirm data write\n",
    "    print(\"written: \" + outputPath + \"\\n\") \n",
    "    \n",
    "    #append data to DFPerCapitaList list\n",
    "    DFPerCapitaList.append(dataDF)\n",
    "    \n",
    "for i in DFPerCapitaList:\n",
    "    print(i.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat all totalPerYear datafranes\n",
    "CasesTotalPerYearConcat = pd.concat(DFTotalList)\n",
    "#establish csv write path\n",
    "outputPath = \"inputData/mergedLists/\" + \"CasesTotalPerYearConcat.csv\"\n",
    "#write csv\n",
    "CasesTotalPerYearConcat.to_csv(outputPath)\n",
    "#confirm data write\n",
    "print(\"written: \" + \"CasesTotalPerYearConcat\" + \"\\n\") \n",
    "\n",
    "\n",
    "#Concat all totalPerYear datafranes\n",
    "CasesPerCapitaPerYearConcat = pd.concat(DFPerCapitaList)\n",
    "#establish csv write path\n",
    "outputPath = \"inputData/mergedLists/\" + \"CasesPerCapitaPerYearConcat.csv\"\n",
    "#write csv\n",
    "CasesPerCapitaPerYearConcat.to_csv(outputPath)\n",
    "#confirm data write\n",
    "print(\"written: \" + \"CasesPerCapitaPerYearConcat\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge into master\n",
    "MasterDF = pd.merge(CasesTotalPerYearConcat, CasesPerCapitaPerYearConcat, on=[\"state_name\", \"year\", \"disease\"])\n",
    "#MasterDF\n",
    "#establish csv write path\n",
    "outputPath = \"inputData/mergedLists/\" + \"MasterDF.csv\"\n",
    "#write csv\n",
    "MasterDF.to_csv(outputPath)\n",
    "#confirm data write\n",
    "print(\"written: \" + \"MasterDF\" + \"\\n\")\n",
    "\n",
    "#READ CSV AS FILE TO PUSH TO POSTGRESQL\n",
    "df = pd.read_csv(outputPath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQLAlchemy\n",
    "\n",
    "engine = create_engine('postgres://gxxdlokrikmuew:56373f2fbd48e1486f270abfc7bb86988844e9210a50f1e66a9055d3c86d61de@ec2-107-22-238-186.compute-1.amazonaws.com:5432/da78e6ihkq1cnl', echo=False)\n",
    "\n",
    "# Sets an object to utilize the default declarative base in SQL Alchemy\n",
    "\n",
    "DBase = declarative_base()\n",
    "\n",
    "class User(DBase):\n",
    "    __tablename__ = 'master'\n",
    "    id = Column(Integer, primary_key=True)\n",
    "    state_name = Column(String(255))\n",
    "    year = Column(Integer)\n",
    "    disease  = Column(String(255))\n",
    "    cases = Column()\n",
    "    incidence_per_capita = Column()        \n",
    "\n",
    "# reflect an existing database into a new model\n",
    "#Base = automap_base()\n",
    "# reflect the tables\n",
    "#DBase.prepare(engine, reflect=True)\n",
    "# We can view all of the classes that automap found\n",
    "\n",
    "#write to table\n",
    "df.to_sql(\"master\", con=engine, if_exists='replace')\n",
    "#MasterDF.to_sql(\"MasterTable\", con=engine, if_exists='replace')\n",
    "\n",
    "#with engine.connect() as con:\n",
    " #   con.execute(\"ALTER TABLE MasterTable ADD PRIMARY KEY (id);\")\n",
    "#print(DBase.classes.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base = automap_base()\n",
    "#Base.prepare(engine, reflect=True)\n",
    "#print(Base.classes)\n",
    "\n",
    "#session = Session(engine)\n",
    "#session.query(MasterTable).all()\n",
    "\n",
    "#conn = engine.connect()\n",
    "#details = engine.execute(\"SELECT * from quiet-coast-48840.MasterTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#engine = create_engine('postgres://gxxdlokrikmuew:56373f2fbd48e1486f270abfc7bb86988844e9210a50f1e66a9055d3c86d61de@ec2-107-22-238-186.compute-1.amazonaws.com:5432/da78e6ihkq1cnl', echo=False)\n",
    "df = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3']})\n",
    "df\n",
    "df.to_sql(\"test\", con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine.execute(\"SELECT * FROM test\").fetchall()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = engine.execute(\"SELECT * FROM master\").fetchall()\n",
    "\n",
    "\n",
    "engine.execute ('ALTER TABLE \"master\" ADD PRIMARY_KEY state_name;')\n",
    "\n",
    "#Base = automap_base()\n",
    "#Base.prepare(engine, reflect=True)\n",
    "#Base.classes.keys()\n",
    "\n",
    "#for item in a:\n",
    "#    print(item)\n",
    "\n",
    "\n",
    "#engine = create_engine('postgres://gxxdlokrikmuew:56373f2fbd48e1486f270abfc7bb86988844e9210a50f1e66a9055d3c86d61de@ec2-107-22-238-186.compute-1.amazonaws.com:5432/da78e6ihkq1cnl')\n",
    "#Base=automap_base()\n",
    "#Base.prepare(engine, reflect=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#engine.execute('DROP TABLE mastertable;')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2 \n",
    "import io\n",
    "\n",
    "engine = create_engine('postgres://gxxdlokrikmuew:56373f2fbd48e1486f270abfc7bb86988844e9210a50f1e66a9055d3c86d61de@ec2-107-22-238-186.compute-1.amazonaws.com:5432/da78e6ihkq1cnl')\n",
    "\n",
    "MasterDF.to_sql('MasterTable', engine, if_exists='replace',index=False) #truncates the table\n",
    "\n",
    "conn = engine.raw_connection()\n",
    "cur = conn.cursor()\n",
    "output = io.StringIO()\n",
    "MasterDF.to_csv(output, header=False, index=False)\n",
    "output.seek(0)\n",
    "contents = output.getvalue()\n",
    "cur.copy_from(output, 'MasterTable', null=\"\") # null values become ''\n",
    "conn.commit()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
